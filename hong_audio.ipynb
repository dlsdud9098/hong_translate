{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/home/apic/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/speaker-diarization-3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     use_auth_token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# run the pipeline on an audio file\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m diarization \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./downloaded_audio/1.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/core/pipeline.py:327\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessors\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    325\u001b[0m     file \u001b[38;5;241m=\u001b[39m ProtocolFile(file, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessors)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_diarization.py:523\u001b[0m, in \u001b[0;36mSpeakerDiarization.apply\u001b[0;34m(self, file, num_speakers, min_speakers, max_speakers, return_embeddings, hook)\u001b[0m\n\u001b[1;32m    520\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinarized_segmentations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_exclude_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m     hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, embeddings)\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m#   shape: (num_chunks, local_num_speakers, dimension)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_diarization.py:348\u001b[0m, in \u001b[0;36mSpeakerDiarization.get_embeddings\u001b[0;34m(self, file, binary_segmentations, exclude_overlap, hook)\u001b[0m\n\u001b[1;32m    345\u001b[0m mask_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(masks)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# (batch_size, num_frames) torch.Tensor\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m embedding_batch: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwaveform_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_batch\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# (batch_size, dimension) np.ndarray\u001b[39;00m\n\u001b[1;32m    353\u001b[0m embedding_batches\u001b[38;5;241m.\u001b[39mappend(embedding_batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:702\u001b[0m, in \u001b[0;36mPyannoteAudioPretrainedSpeakerEmbedding.__call__\u001b[0;34m(self, waveforms, masks)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    701\u001b[0m             warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m             embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwaveforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/models/embedding/wespeaker/__init__.py:343\u001b[0m, in \u001b[0;36mBaseWeSpeakerResNet.forward\u001b[0;34m(self, waveforms, weights)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract speaker embeddings\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Batch of embeddings.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m fbank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_fbank(waveforms)\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfbank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/models/embedding/wespeaker/resnet.py:416\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, fbank, weights)\u001b[0m\n\u001b[1;32m    414\u001b[0m fbank \u001b[38;5;241m=\u001b[39m fbank\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    415\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(fbank)))\n\u001b[0;32m--> 416\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m    418\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/models/embedding/wespeaker/resnet.py:141\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 141\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n\u001b[1;32m    143\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hong_venv/lib/python3.11/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from glob import glob\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "with open('./token.txt', encoding='utf-8') as f:\n",
    "    use_auth_token = f.read()\n",
    "    \n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token = use_auth_token\n",
    "    )\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"./downloaded_audio/1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./downloaded_audio (ì‚¬ë³¸)/#1-1 ì½©ì§„í˜¸ì˜ íŒŒì´ë„ í•´ì„¤ Jinho Hong comments on his play of APT TAIWAN 2019 ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/#1-2. ì½©ì§„í˜¸ì˜ íŒŒì´ë„ í•´ì„¤ Jinho Hong comments on his play of APT TAIWAN 2019 ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/#1-3. ì½©ì§„í˜¸ì˜ íŒŒì´ë„ í•´ì„¤ Jinho Hong comments on his play of APT TAIWAN 2019 ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/#1-4. ì½©ì§„í˜¸ì˜ íŒŒì´ë„ í•´ì„¤ Jinho Hong comments on his play of APT TAIWAN 2019 ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/2023 ì½©ì½©ì ˆ í™ì§„í˜¸ì˜ ì¸í„°ë·°.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/40ëŒ€ í™ì§„í˜¸ëŠ” ì‹ ì¡°ì–´ë¥¼ ì–¼ë§ˆë‚˜ ì•Œê¹Œï¼Ÿ.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[FULL] 2ë¡œ 2ë“±ì´ ê²°ì •ëœë‹¤ê³ ï¼Ÿï¼Ÿï¼Ÿ Jinho Hong Comments on his play, APT Taiwan 2019 Main Event.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[vlog] #00 ï¼š ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì§€ê¸ˆ ë§ˆë‹ë¼ìž…ë‹ˆë‹¤  ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[vlog] #01 ï¼š 1ë“±ìž…ë‹ˆë‹¤ ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[vlog] #02 ï¼š ìš°ìŠ¹ë…¼ëž€(ï¼Ÿ) í•´ëª…í•˜ê² ìŠµë‹ˆë‹¤ ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[vlog] #03 ï¼š ì£„ì†¡í•©ë‹ˆë‹¤... 2ë“±ì„ ìˆ¨ê²¼ìŠµë‹ˆë‹¤... ï½œ í™ì§„í˜¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[vlog] ì´ëŸ°ê±°ë¼ë„ ì˜¬ë¦¬ëŠ”ê²Œ ë‚«ì§€ì•Šê² ã„´ã…‡~~.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[ê³¨ë¼ë´ì•¼ì§€] ë°œìŒì´ ì•ˆ ì¢‹ì•„ë„ ê´œì°®ì•„, ì¶”ë¦¬ëŠ” ìµœê³ ë‹ˆê¹Œâ˜† í™ì§„í˜¸ ë°œìŒ ëª¨ìŒã…£í¬ë¼ìž„ì”¬ã…£JTBC 170714 ë°©ì†¡ ì™¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[ë”ìŠ¤í…Œì´ì§€] ì´¬ì˜í˜„ìž¥ ë’·ì´ì•¼ê¸°&ì¸í„°ë·° (í™ì§„í˜¸, ì‹ ì‚¬ìž„ë‹¹, ìŠ¹ìš°ì•„ë¹ , ìŠˆì¹´, ê½ˆëšœë£¹, ê³µí˜ì¤€, ë…¼ë¦¬ì™•ì „ê¸°).wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[ë¼ë””ì˜¤ìŠ¤íƒ€] ì•Œê³  ë³´ë©´ ì„œë°”ì´ë²Œê³„ ì´ˆëŒ€ ëŒ€í†µë ¹ðŸ˜Ž í•­ìƒ ì§„ì‹¤ëœ í”Œë ˆì´ë¥¼ í•˜ëŠ” í™ì§„í˜¸, MBC 250226 ë°©ì†¡.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[ì†ë³´] í™ì§„í˜¸ ï¼‚ ë‚´ê°€ ìž„ìš”í™˜ë³´ë‹¤ ìœ„ë‹¤ ï¼‚ ì¸í„°ë·° feat. PSG BMW.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/[í”¼ì˜ ê²Œìž„3] ë¦´ë ˆì´ ì§€ëª© ì¸í„°ë·°ðŸŽ¤ - í™ì§„í˜¸.wav',\n",
       " \"./downloaded_audio (ì‚¬ë³¸)/ëŒ„ì‹±ë¨¸ì‹  í™ì§„í˜¸ì˜ 'í•œë‹¨ì–´ ì¸í„°ë·°' ë‚˜ë„ê¶ê¸ˆí•´!.wav\",\n",
       " './downloaded_audio (ì‚¬ë³¸)/ë§¹ìŠ¹ì§€ì˜ ë˜˜ì§êµ¬ ì¸í„°ë·° í™ì§„í˜¸íŽ¸.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/ë°°í… ë§‰ë°© ë…¹ìŒ ë©”ì´í‚¹í•„ë¦„ (with ë°°í…ì‹êµ¬ë“¤).wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/í¬ì»¤ ì‹ ë“¤ì˜ì „ìŸ[EP.1] ë¦¬ë·°&ë¹„í•˜ì¸ë“œ ì°(feat.ê¹€ê°‘ìš©).wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/í¬ì»¤ ì‹ ë“¤ì˜ì „ìŸ[EP.2] ë¦¬ë·°&ë¹„í•˜ì¸ë“œ ì°(feat.ê¹€ê°‘ìš©).wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/í­í’ì €ê·¸ í™ì§„í˜¸ê°€ ì €ê·¸ìœ ë‹›ì„ ì§ì ‘ ë§Œë‚œë‹¤ë©´ï¼Ÿ.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/í™ì§„í˜¸ì”¨ ì½©ì§„í˜¸ê°€ ì•„ë‹ˆê³  í™ì§„í˜¸ìž…ë‹ˆë‹¤ ã…‹ã…‹.wav',\n",
       " './downloaded_audio (ì‚¬ë³¸)/í™ì§„í˜¸ì˜ MBTI ì„±ê²©ìœ í˜•ì€ï¼Ÿ (with í™ì§„í˜¸ì˜ TMI).wav']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìŒì„± íŒŒì¼ ì´ë¦„ ë³€ê²½\n",
    "# audio_list = sorted(glob('./downloaded_audio/*'))\n",
    "audio_list = sorted(glob('./downloaded_audio (ì‚¬ë³¸)/*'))\n",
    "audio_list\n",
    "\n",
    "# for idx, audio in enumerate(audio_list):\n",
    "#     original_name = f\"./downloaded_audio/{os.path.basename(audio)}\"\n",
    "#     new_name = f'./downloaded_audio/{idx + 1}.wav'\n",
    "    \n",
    "#     os.rename(original_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=use_auth_token)\n",
    "\n",
    "diarization = pipeline(\"./downloaded_audio(ì‚¬ë³¸)/[ê³¨ë¼ë´ì•¼ì§€] ë°œìŒì´ ì•ˆ ì¢‹ì•„ë„ ê´œì°®ì•„, ì¶”ë¦¬ëŠ” ìµœê³ ë‹ˆê¹Œâ˜† í™ì§„í˜¸ ë°œìŒ ëª¨ìŒã…£í¬ë¼ìž„ì”¬ã…£JTBC 170714 ë°©ì†¡ ì™¸.wav\")\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"{turn.start:.1f} --> {turn.end:.1f} {speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",use_auth_token=use_auth_token)\n",
    "\n",
    "# inference on the whole file\n",
    "pipeline(\"./downloaded_audio(ì‚¬ë³¸)/[ê³¨ë¼ë´ì•¼ì§€] ë°œìŒì´ ì•ˆ ì¢‹ì•„ë„ ê´œì°®ì•„, ì¶”ë¦¬ëŠ” ìµœê³ ë‹ˆê¹Œâ˜† í™ì§„í˜¸ ë°œìŒ ëª¨ìŒã…£í¬ë¼ìž„ì”¬ã…£JTBC 170714 ë°©ì†¡ ì™¸.wav\")\n",
    "\n",
    "# inference on an excerpt\n",
    "from pyannote.core import Segment\n",
    "excerpt = Segment(start=2.0, end=5.0)\n",
    "\n",
    "from pyannote.audio import Audio\n",
    "waveform, sample_rate = Audio().crop(\"file.wav\", excerpt)\n",
    "pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apic/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/apic/miniconda3/envs/hong_venv/lib/python3.11/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token = use_auth_token\n",
    "  )\n",
    "\n",
    "pipeline.to(torch.device(\"cuda\")) # GPU ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"./downloaded_audio/1.wav\")\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5093 6241 SPEAKER_00\n",
      "8350 8890 SPEAKER_00\n",
      "9346 36160 SPEAKER_00\n",
      "36397 48429 SPEAKER_00\n",
      "48901 50251 SPEAKER_00\n",
      "50504 54807 SPEAKER_00\n",
      "55246 59313 SPEAKER_00\n",
      "59701 61186 SPEAKER_00\n",
      "61388 63429 SPEAKER_00\n",
      "63835 64729 SPEAKER_00\n",
      "65303 67294 SPEAKER_00\n",
      "67902 69826 SPEAKER_00\n",
      "69910 70787 SPEAKER_00\n",
      "71108 76441 SPEAKER_00\n",
      "76762 82972 SPEAKER_00\n",
      "77015 77201 SPEAKER_01\n",
      "83343 85115 SPEAKER_00\n",
      "85553 88962 SPEAKER_00\n",
      "89215 94834 SPEAKER_00\n",
      "95324 98277 SPEAKER_00\n",
      "98800 103744 SPEAKER_00\n",
      "104234 105550 SPEAKER_00\n",
      "106327 107711 SPEAKER_00\n",
      "108250 109381 SPEAKER_00\n",
      "110073 111879 SPEAKER_00\n",
      "112688 114527 SPEAKER_00\n",
      "114747 115439 SPEAKER_00\n",
      "116063 117109 SPEAKER_00\n",
      "117683 118510 SPEAKER_00\n",
      "120468 121700 SPEAKER_00\n",
      "124096 125530 SPEAKER_00\n",
      "126627 128314 SPEAKER_00\n",
      "129850 130542 SPEAKER_00\n",
      "130846 132365 SPEAKER_00\n",
      "132702 135081 SPEAKER_00\n",
      "135318 140380 SPEAKER_00\n",
      "140819 143013 SPEAKER_00\n",
      "145004 147502 SPEAKER_00\n",
      "147805 149357 SPEAKER_00\n",
      "149763 150927 SPEAKER_00\n",
      "151535 158555 SPEAKER_00\n",
      "159196 162520 SPEAKER_00\n",
      "163313 166857 SPEAKER_00\n",
      "167245 168595 SPEAKER_00\n",
      "169169 170587 SPEAKER_00\n",
      "172865 174755 SPEAKER_00\n",
      "175312 178029 SPEAKER_00\n",
      "178366 179969 SPEAKER_00\n",
      "180172 180645 SPEAKER_00\n",
      "180982 182433 SPEAKER_00\n",
      "183108 183985 SPEAKER_00\n",
      "184390 190229 SPEAKER_00\n",
      "184660 185234 SPEAKER_01\n",
      "190617 197839 SPEAKER_00\n",
      "198413 199139 SPEAKER_00\n",
      "199983 206007 SPEAKER_00\n",
      "207104 207880 SPEAKER_00\n",
      "208420 211188 SPEAKER_00\n",
      "211745 212555 SPEAKER_00\n",
      "213230 214884 SPEAKER_00\n",
      "217938 219204 SPEAKER_00\n",
      "220823 221734 SPEAKER_00\n",
      "222730 223270 SPEAKER_00\n",
      "223608 224637 SPEAKER_00\n",
      "225987 228535 SPEAKER_00\n",
      "230155 231016 SPEAKER_00\n",
      "231202 232586 SPEAKER_00\n",
      "235015 235842 SPEAKER_00\n",
      "236568 237378 SPEAKER_00\n",
      "242693 244127 SPEAKER_00\n",
      "245579 246878 SPEAKER_00\n",
      "247604 252886 SPEAKER_00\n",
      "253544 255788 SPEAKER_00\n",
      "256278 257257 SPEAKER_00\n",
      "257728 262993 SPEAKER_00\n",
      "263517 271583 SPEAKER_00\n",
      "271904 274942 SPEAKER_00\n",
      "275245 285252 SPEAKER_00\n",
      "285488 288542 SPEAKER_00\n",
      "288847 290619 SPEAKER_00\n",
      "291445 296997 SPEAKER_00\n",
      "299360 316640 SPEAKER_00\n",
      "317517 318918 SPEAKER_00\n",
      "319643 321584 SPEAKER_00\n",
      "324672 325145 SPEAKER_00\n",
      "325685 327238 SPEAKER_00\n",
      "327490 328216 SPEAKER_00\n",
      "329549 331270 SPEAKER_00\n",
      "331912 333279 SPEAKER_00\n",
      "335759 336434 SPEAKER_00\n",
      "339269 340028 SPEAKER_00\n",
      "340231 341480 SPEAKER_00\n",
      "341868 342948 SPEAKER_00\n",
      "343235 344838 SPEAKER_00\n",
      "345260 347369 SPEAKER_00\n",
      "350322 351571 SPEAKER_00\n",
      "354558 356870 SPEAKER_00\n",
      "357595 358489 SPEAKER_00\n",
      "361122 363080 SPEAKER_00\n",
      "364379 366471 SPEAKER_00\n",
      "366792 370184 SPEAKER_00\n",
      "370808 375314 SPEAKER_00\n",
      "375955 376124 SPEAKER_00\n",
      "377221 380005 SPEAKER_00\n",
      "380630 382031 SPEAKER_00\n",
      "382672 391430 SPEAKER_00\n",
      "391801 397741 SPEAKER_00\n",
      "398433 400964 SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "# ì˜¤ë””ì˜¤ ì‹œê°„ëŒ€ ë¶„ë¦¬í•˜ê¸°\n",
    "with open('./audio.rttm', 'r') as f:\n",
    "    audio_file = f.read()\n",
    "\n",
    "audio_start = []\n",
    "audio_end = []\n",
    "speakers = []\n",
    "\n",
    "for row in audio_file.split('\\n')[:-1]:\n",
    "    start = int(float(row.split(' ')[3]) * 1000)\n",
    "    end = int(float(row.split(' ')[4]) * 1000)\n",
    "    \n",
    "    audio_start.append(start)\n",
    "    audio_end.append(start+end)\n",
    "    speakers.append(row.split(' ')[7])\n",
    "    \n",
    "for start, end, speaker in zip(audio_start, audio_end, speakers):\n",
    "    print(start, end, speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.wav'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sound = AudioSegment.from_file(\"./downloaded_audio/1.wav\")  # ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='combined_example.wav'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for start, end, speaker in zip(audio_start, audio_end, speakers):\n",
    "    pass\n",
    "    \n",
    "    # print(start, end)\n",
    "new_audio = sound[start: end]\n",
    "\n",
    "# print(start, end)\n",
    "new_audio.export(\"combined_example.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./downloaded_audio/1.wav',\n",
       " './downloaded_audio/10.wav',\n",
       " './downloaded_audio/11.wav',\n",
       " './downloaded_audio/12.wav',\n",
       " './downloaded_audio/13.wav',\n",
       " './downloaded_audio/14.wav',\n",
       " './downloaded_audio/15.wav',\n",
       " './downloaded_audio/16.wav',\n",
       " './downloaded_audio/17.wav',\n",
       " './downloaded_audio/18.wav',\n",
       " './downloaded_audio/19.wav',\n",
       " './downloaded_audio/2.wav',\n",
       " './downloaded_audio/20.wav',\n",
       " './downloaded_audio/21.wav',\n",
       " './downloaded_audio/22.wav',\n",
       " './downloaded_audio/23.wav',\n",
       " './downloaded_audio/24.wav',\n",
       " './downloaded_audio/25.wav',\n",
       " './downloaded_audio/3.wav',\n",
       " './downloaded_audio/4.wav',\n",
       " './downloaded_audio/5.wav',\n",
       " './downloaded_audio/6.wav',\n",
       " './downloaded_audio/7.wav',\n",
       " './downloaded_audio/8.wav',\n",
       " './downloaded_audio/9.wav']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì½”ë“œ í•©ì¹˜ê¸°\n",
    "audio_files =sorted(glob('./downloaded_audio/*.wav'))\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token = use_auth_token\n",
    "    )\n",
    "\n",
    "pipeline.to(torch.device(\"cuda\")) # GPU ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "for file in audio_files:\n",
    "    # run the pipeline on an audio file\n",
    "    diarization = pipeline(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hong_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
